{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PhantomWiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PhantomWiki is an on-demand random generator of fictional worlds. Similarly to the wiki hosting services popular in film, video games, and literature [1], we represent these fictional worlds through Wikipedia-like biographical entries about their characters. We then test the modelâ€™s retrieval skills and its understanding of the fictional world through an accompanying set of automatically generated question-answer pairs.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"assets/PhantomWiki-pipeline.png\" alt=\"PhantomWiki Pipeline\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generate a PhantomWiki Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of the PhantomWiki pipeline is to generate a random universe of characters as well as the document corpus describing it. \n",
    "\n",
    "Each character in a PhantomWiki universe is described through its social relationships and personal facts. For the social relationships, we first generate family trees, following the family tree generator of Hohenecker & Lukasiewicz (2020)[2]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This family tree generation algorithm allows us to specify the parameters (for more please refer to our source code) for family tree generation: \n",
    "- `num-family-trees`: the number of family trees in a PhantomWiki universe \n",
    "- `max-family-tree-size`: the maximum number of people in one family tree \n",
    "\n",
    "These two parameters together determine the size of the universe, i.e., the number of characters: `universe-size = num-family-trees * max-family-tree-size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_family_trees = 1\n",
    "max_family_tree_size = 25\n",
    "# universe size is 1 * 25 = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next specify the complexity of questions generated about this universe with `question-depth`. Questions are generated from question templates, obtained by recursively unrolling the Context-Free Grammar. Here, `question-depth` determines the maximum number of times the CFG will be unrolled. The difficulty of generated questions is proportional to this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_depth = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the folder and subfolder (for different splits) you want to store your PhantomWiki instance (including facts, QA pairs.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_dir = \"out\"\n",
    "split = \"split0\"\n",
    "split_dir = os.path.join(output_dir, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the following command to generate a PhantomWiki universe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install phantom-wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!phantom-wiki-generate --output-dir $split_dir --question-depth $question_depth --num-family-trees $num_family_trees --max-family-tree-size $max_family_tree_size --article-format json --question-format json --debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Visualization of the PhantomWiki universe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have generated a universe with PhantomWiki stored in the `$output_dir` folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Visualization of family trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can first take a look at the family trees we generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default we are showing the first family tree generated, although more may be generated at the last step.\n",
    "family_tree_file = f\"{split_dir}/family_tree_1.png\"\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(filename=family_tree_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every person in PhantomWiki has a first name and a last name. Colors indicate the gender of people in the PhantomWiki universe. Arrows indicate parental relationship. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Generated Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The facts generated besides the family relationships include friend relationships, hobbies, occupations for the people in the universe. These facts are stored in `facts.pl` and used when converted into articles. \n",
    "\n",
    "Those facts are converted into articles for everyone using pre-defined templates. \n",
    "Articles generated are saved in `articles.json`. Each person has an entry in the JSON file with the article's title, content, and their associated facts. (For family relationships only the parents and siblings information are mentioned in the articles.)\n",
    "\n",
    "Here we can take a look at an example of generated articles:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input the name of the person you want to read the article about\n",
    "import json\n",
    "\n",
    "name = \"Aida Wang\"\n",
    "article_file = f\"{output_dir}/articles.json\"\n",
    "with open(article_file, \"r\") as f:\n",
    "    article_file = json.load(f)\n",
    "    for entry in article_file:\n",
    "        if entry[\"title\"] == name:\n",
    "            article = entry[\"article\"]\n",
    "            print(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Generated QA pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each PhantomWiki instance also contains Question-Answer pairs that are consistent with the generated facts. \n",
    "\n",
    "According to our CFG's construction, using `--question-depth 10` gives us `8` types of question templates. The number of questions generated from each type of template can be specified via `--num-questions-per-type` (default is `10`). These questions are stored in `questions.json` arranged by template type. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at some of the questions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the type of question you want to look at\n",
    "type = 0\n",
    "question_file = f\"{output_dir}/questions.json\"\n",
    "import json\n",
    "\n",
    "with open(question_file, \"r\") as f:\n",
    "    questions = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can look at the result of a sampled question and its answer along with the original question template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = questions[0]\n",
    "print(\"Question: \", question[\"question\"])\n",
    "print(\"Answer: \", question[\"answer\"])\n",
    "print(\"Prolog:\", question[\"prolog\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `prolog` key shows the prolog query needed to get the answer of a certain question. For users who have more interest in Prolog, please refer to [3]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation on a PhantomWiki instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Run evaluation with specific model and method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the evaluation dependencies\n",
    "!pip install phantom-wiki[eval]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a dataset from HuggingFace or from a local folder: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phantom_eval.utils import load_data\n",
    "\n",
    "# The dataset we just generated can be loaded by\n",
    "dataset = load_data(dataset=output_dir, split=split, from_local=True)\n",
    "\n",
    "# For convenience of development, we provide pre-generated datasets on Huggingface\n",
    "HF_version = \"kilian-group/phantom-wiki-v1\"\n",
    "HF_split = \"depth_20_size_50_seed_1\"\n",
    "dataset = load_data(dataset=HF_version, split=HF_split, from_local=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finally run evaluation on the generated PhantomWiki dataset. As an example, we test the `zeroshot` method using a gpt model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"zeroshot\"\n",
    "model = \"gpt-4o-mini-2024-07-18\"\n",
    "preds_dir = \"out-evals\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to run evaluation on the generated PhantomWiki instance\n",
    "# !python -m phantom_eval --method $method -od $preds_dir -m $model --from_local --dataset $output_dir --split_list $split\n",
    "\n",
    "# to run evaluation on a HuggingFace Dataset\n",
    "!python -m phantom_eval --method $method -od $preds_dir -m $model --dataset $HF_version --split_list $HF_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Visualize the reasoning evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can summarize the evaluation results. Moreover, we can also visualize LLM performance as a function of question difficulty. Since the dataset contains questions of varying difficulty (i.e. requiring different number of reasoning steps to answer), we can visualize F1 score v Reasoning Steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python eval/format_leaderboard.py -od $preds_dir --dataset $HF_version --method_list $method --model_list $model\n",
    "\n",
    "!python eval/plot_reasoning.py -od $preds_dir --dataset $HF_version --model_list $model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- [1] For example, see stardewvalley.fandom.com or harrypotter.fandom.com.\n",
    "- [2] Hohenecker, Patrick, and Thomas Lukasiewicz. \"Ontology reasoning with deep neural networks.\" Journal of Artificial Intelligence Research 68 (2020): 503-540.\n",
    "- [3] Sterling, Leon, and Ehud Y. Shapiro. The art of Prolog: advanced programming techniques. MIT press, 1994. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phantom-wiki",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
