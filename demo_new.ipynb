{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PhantomWiki is at its core an on-demand random generator of fictional worlds. Similarly to the wiki hosting services popular in film, video games, and literature[1], we represent these fictional worlds through Wikipedia-like biographical entries about their characters. We then test the modelâ€™s retrieval skills and its understanding of the fictional world through an accompanying set of automatically generated question-answer pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generate a PhantomWiki Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of the PhantomWiki pipeline is to generate a random universe of n characters as well as the document corpus describing it. \n",
    "\n",
    "\n",
    "Each character in a PhantomWiki universe is described through its social relationships and personal facts. For the social relationships,\n",
    "we first generate family trees, following the family tree generator of Hohenecker & Lukasiewicz (2020)[2].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This family tree generation algorithm allows us to specify the parameters (for more please refer to our source code) for family tree generation: \n",
    "<br>\n",
    "<br>\n",
    "`num-family-trees`: the number of family trees in a PhantomWiki universe \n",
    "<br>\n",
    "`max-family-tree-size`: the maximum number of people in one family tree \n",
    "<br>\n",
    "`max-branching-factor`: the maximum depth that a family tree may have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_family_trees = 1\n",
    "max_family_tree_size = 25\n",
    "max_branching_factor = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the folder and subfolder (for different splits) you want to store your PhantomWiki instance (including facts, QA pairs.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_dir = \"out\"\n",
    "split = \"split0\"\n",
    "split_dir = os.path.join(output_dir, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the following command to generate a PhantomWiki universe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m phantom_wiki --num-family-trees $num_family_trees --max-family-tree-size $max_family_tree_size --max-branching-factor $max_branching_factor --output-dir $split_dir --article-format json --question-format json  --valid-only --debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Visualization of the PhantomWiki universe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have generated a universe with PhantomWiki stored in the `$output_dir` folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Visualization of family trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can first take a look at the family trees we generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default we are showing the first family tree generated, although more may be generated at the last step.\n",
    "family_tree_file = f\"{output_dir}/family_tree_1.png\"\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(filename=family_tree_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every person in PhantomWiki has a first name and a last name. Colors indicate the gender of people in the PhantomWiki universe. Arrows indicate parental relationship. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Generated Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The facts generated besides the family relationships include friend relationships, hobbies, occupations for the people in the universe. These facts are stored in `facts.pl` and used when converted into articles. \n",
    "\n",
    "Those facts are converted into articles for everyone using pre-defined templates. \n",
    "Articles generated are saved in `articles` folder. Each person has a `$name.txt` file associated listing the related facts of this person. (For family relationships only the parents and siblings information are relected in the articles.)\n",
    "\n",
    "Here we can take a look at an example of generated articles:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input the name of the person you want to read the article about\n",
    "import json\n",
    "\n",
    "name = \"Aida Wang\"\n",
    "article_file = f\"{output_dir}/articles.json\"\n",
    "with open(article_file, \"r\") as f:\n",
    "    article_file = json.load(f)\n",
    "    for entry in article_file:\n",
    "        if entry[\"title\"] == name:\n",
    "            article = entry[\"article\"]\n",
    "            print(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Generated QA pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each PhantomWiki instance also contains Question-Answer pairs that are consistent with the generated facts. \n",
    "\n",
    "The difficulty of the generated questions is tunable via the `--depth` when running `python -m phantom_wiki` command above. by default, using `--depth 10` gives us `8` types of question templates. The number of questions generated from each type of template can be specified via `--num-questions-per-type` (default is 10). These questions are stored in `questions` folder arraged by type. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at some of the questions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the type of question you want to look at\n",
    "type = 0\n",
    "question_file = f\"{output_dir}/questions.json\"\n",
    "import json\n",
    "\n",
    "with open(question_file, \"r\") as f:\n",
    "    questions = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can look at the result of a sampled question and its answer along with the original question template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = questions[0]\n",
    "print(\"Question: \", question[\"question\"])\n",
    "print(\"Answer: \", question[\"answer\"])\n",
    "print(\"Prolog:\", question[\"prolog\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `prolog` key shows the prolog query needed to get the answer of a certain question. For users who have more interest in Prolog, please refer to [3]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation on a PhantomWiki instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Run evaluation with specific model and method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a dataset from HuggingFace or from a local folder: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phantom_eval.utils import load_data\n",
    "\n",
    "# The dataset we just generated can be loaded by\n",
    "# dataset = load_data(dataset=output_dir, split=split, from_local=True)\n",
    "\n",
    "# If you want to load a HuggingFace dataset\n",
    "HF_version = \"kilian-group/phantom-wiki-v050\"\n",
    "# Note that the HuggingFace splits follow the following format\n",
    "HF_split = \"depth_20_size_50_seed_1\"\n",
    "dataset = load_data(dataset=HF_version, split=HF_split, from_local=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finally run evaluation on the generated PhantomWiki dataset. As an example, we test the `zeroshot` method using a gpt model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"zeroshot\"\n",
    "model = \"gpt-4o-mini-2024-07-18\"\n",
    "preds_dir = \"preds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to run evaluation on the generated PhantomWiki instance\n",
    "!python -m phantom_eval --method $method -od $preds_dir -m $model --from_local --dataset $output_dir --split_list $split\n",
    "\n",
    "# to run evaluation on a HuggingFace Dataset\n",
    "!python -m phantom_eval --method $method -od $preds_dir -m $model --dataset $HF_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use functionalities for evaluation to plot the method tested on a PhamtomWiki instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the accuracy vs. reasoning steps for the predictions\n",
    "!python eval/plot_difficulty_accuracy.py -od $preds_dir --method $method --depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] For example, see stardewvalley.fandom.com or harrypotter.fandom.com. \\\n",
    "[2] Hohenecker, Patrick, and Thomas Lukasiewicz. \"Ontology reasoning with deep neural networks.\" Journal of Artificial Intelligence Research 68 (2020): 503-540.\n",
    "[3] Sterling, Leon, and Ehud Y. Shapiro. The art of Prolog: advanced programming techniques. MIT press, 1994. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phantom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
